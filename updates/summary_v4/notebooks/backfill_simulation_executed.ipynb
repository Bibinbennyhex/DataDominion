{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backfill Simulation - Summary Pipeline v4.0\n",
    "\n",
    "This notebook demonstrates the **backfill capability** of the Summary Pipeline v4.0.\n",
    "\n",
    "## What is Backfill?\n",
    "Backfill handles **late-arriving data** - when new records arrive for a historical month that was already processed.\n",
    "\n",
    "### Scenario\n",
    "1. We have processed months 2024-01 through 2024-06\n",
    "2. New data arrives for 2024-03 (with a newer timestamp)\n",
    "3. The pipeline must:\n",
    "   - Detect the newer records\n",
    "   - Update the 2024-03 summary rows\n",
    "   - Rebuild the rolling history arrays for all affected accounts\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T16:45:15.806691Z",
     "iopub.status.busy": "2026-01-21T16:45:15.805899Z",
     "iopub.status.idle": "2026-01-21T16:45:21.665475Z",
     "shell.execute_reply": "2026-01-21T16:45:21.664227Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/21 16:45:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/21 16:45:20 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "26/01/21 16:45:20 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "26/01/21 16:45:20 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "26/01/21 16:45:20 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Version: 3.5.5\n",
      "Session started at: 2026-01-21 16:45:21.661184\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from datetime import datetime\n",
    "\n",
    "# Create Spark session with Iceberg support\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"BackfillSimulation\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(f\"Spark Version: {spark.version}\")\n",
    "print(f\"Session started at: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Check Current State (BEFORE Backfill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T16:45:21.671019Z",
     "iopub.status.busy": "2026-01-21T16:45:21.669259Z",
     "iopub.status.idle": "2026-01-21T16:46:09.300033Z",
     "shell.execute_reply": "2026-01-21T16:46:09.297887Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CURRENT TABLE COUNTS\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accounts_all:   5,990 records\n",
      "summary:        5,950 records\n",
      "latest_summary: 1,000 records\n"
     ]
    }
   ],
   "source": [
    "# Check table counts\n",
    "print(\"=\" * 60)\n",
    "print(\"CURRENT TABLE COUNTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "accounts_count = spark.sql(\"SELECT COUNT(*) as cnt FROM default.default.accounts_all\").collect()[0]['cnt']\n",
    "summary_count = spark.sql(\"SELECT COUNT(*) as cnt FROM default.summary\").collect()[0]['cnt']\n",
    "latest_count = spark.sql(\"SELECT COUNT(*) as cnt FROM default.latest_summary\").collect()[0]['cnt']\n",
    "\n",
    "print(f\"accounts_all:   {accounts_count:,} records\")\n",
    "print(f\"summary:        {summary_count:,} records\")\n",
    "print(f\"latest_summary: {latest_count:,} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T16:46:09.307751Z",
     "iopub.status.busy": "2026-01-21T16:46:09.306904Z",
     "iopub.status.idle": "2026-01-21T16:46:13.350082Z",
     "shell.execute_reply": "2026-01-21T16:46:13.348403Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RECORDS BY MONTH\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+\n",
      "|  month|summary_records|\n",
      "+-------+---------------+\n",
      "|2024-01|           1000|\n",
      "|2024-02|           1000|\n",
      "|2024-03|            990|\n",
      "|2024-04|            981|\n",
      "|2024-05|            979|\n",
      "|2024-06|           1000|\n",
      "+-------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check records by month\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RECORDS BY MONTH\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT rpt_as_of_mo as month, COUNT(*) as summary_records\n",
    "    FROM default.summary\n",
    "    GROUP BY rpt_as_of_mo\n",
    "    ORDER BY rpt_as_of_mo\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Select Accounts for Backfill Simulation\n",
    "\n",
    "We'll pick 5 accounts to demonstrate the backfill. Let's see their current state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T16:46:13.354939Z",
     "iopub.status.busy": "2026-01-21T16:46:13.354497Z",
     "iopub.status.idle": "2026-01-21T16:46:13.363604Z",
     "shell.execute_reply": "2026-01-21T16:46:13.361845Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accounts selected for backfill: [11, 12, 13, 14, 15]\n",
      "Month to backfill: 2024-03\n"
     ]
    }
   ],
   "source": [
    "# Define accounts to backfill (accounts 11-15 to avoid previous test data)\n",
    "BACKFILL_ACCOUNTS = [11, 12, 13, 14, 15]\n",
    "BACKFILL_MONTH = '2024-03'  # We'll backfill March 2024\n",
    "\n",
    "print(f\"Accounts selected for backfill: {BACKFILL_ACCOUNTS}\")\n",
    "print(f\"Month to backfill: {BACKFILL_MONTH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T16:46:13.369041Z",
     "iopub.status.busy": "2026-01-21T16:46:13.368550Z",
     "iopub.status.idle": "2026-01-21T16:45:37.619640Z",
     "shell.execute_reply": "2026-01-21T16:45:37.618079Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "BEFORE BACKFILL - State for 2024-03\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cons_acct_key</th>\n",
       "      <th>rpt_as_of_mo</th>\n",
       "      <th>past_due_am</th>\n",
       "      <th>days_past_due</th>\n",
       "      <th>balance_am</th>\n",
       "      <th>payment_history_grid</th>\n",
       "      <th>past_due_latest</th>\n",
       "      <th>dpd_latest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>2024-03</td>\n",
       "      <td>38524</td>\n",
       "      <td>48</td>\n",
       "      <td>80259</td>\n",
       "      <td>110?????????????????????????????????</td>\n",
       "      <td>38524</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>2024-03</td>\n",
       "      <td>14903</td>\n",
       "      <td>21</td>\n",
       "      <td>70968</td>\n",
       "      <td>000?????????????????????????????????</td>\n",
       "      <td>14903</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>2024-03</td>\n",
       "      <td>9657</td>\n",
       "      <td>16</td>\n",
       "      <td>60361</td>\n",
       "      <td>000?????????????????????????????????</td>\n",
       "      <td>9657</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>2024-03</td>\n",
       "      <td>27889</td>\n",
       "      <td>74</td>\n",
       "      <td>55779</td>\n",
       "      <td>200?????????????????????????????????</td>\n",
       "      <td>27889</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>2024-03</td>\n",
       "      <td>56596</td>\n",
       "      <td>41</td>\n",
       "      <td>138040</td>\n",
       "      <td>100?????????????????????????????????</td>\n",
       "      <td>56596</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cons_acct_key rpt_as_of_mo  past_due_am  days_past_due  balance_am  \\\n",
       "0             11      2024-03        38524             48       80259   \n",
       "1             12      2024-03        14903             21       70968   \n",
       "2             13      2024-03         9657             16       60361   \n",
       "3             14      2024-03        27889             74       55779   \n",
       "4             15      2024-03        56596             41      138040   \n",
       "\n",
       "                   payment_history_grid  past_due_latest  dpd_latest  \n",
       "0  110?????????????????????????????????            38524          48  \n",
       "1  000?????????????????????????????????            14903          21  \n",
       "2  000?????????????????????????????????             9657          16  \n",
       "3  200?????????????????????????????????            27889          74  \n",
       "4  100?????????????????????????????????            56596          41  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store BEFORE state for comparison\n",
    "before_df = spark.sql(f\"\"\"\n",
    "    SELECT \n",
    "        cons_acct_key,\n",
    "        rpt_as_of_mo,\n",
    "        past_due_am,\n",
    "        days_past_due,\n",
    "        balance_am,\n",
    "        payment_history_grid,\n",
    "        past_due_am_history[0] as past_due_latest,\n",
    "        days_past_due_history[0] as dpd_latest\n",
    "    FROM default.summary\n",
    "    WHERE cons_acct_key IN ({','.join(map(str, BACKFILL_ACCOUNTS))})\n",
    "      AND rpt_as_of_mo = '{BACKFILL_MONTH}'\n",
    "    ORDER BY cons_acct_key\n",
    "\"\"\")\n",
    "\n",
    "before_state = before_df.toPandas()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"BEFORE BACKFILL - State for {BACKFILL_MONTH}\")\n",
    "print(\"=\" * 80)\n",
    "before_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T16:45:37.626180Z",
     "iopub.status.busy": "2026-01-21T16:45:37.625204Z",
     "iopub.status.idle": "2026-01-21T16:45:38.326256Z",
     "shell.execute_reply": "2026-01-21T16:45:38.324779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current source data timestamps:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+-----------+-------------+--------------------------+\n",
      "|cons_acct_key|rpt_as_of_mo|past_due_am|days_past_due|base_ts                   |\n",
      "+-------------+------------+-----------+-------------+--------------------------+\n",
      "|11           |2024-03     |38524      |48           |2025-09-23 12:41:34.009371|\n",
      "|12           |2024-03     |14903      |21           |2025-09-23 12:41:34.009371|\n",
      "|13           |2024-03     |9657       |16           |2025-09-23 12:41:34.009371|\n",
      "|14           |2024-03     |27889      |74           |2025-09-23 12:41:34.009371|\n",
      "|15           |2024-03     |56596      |41           |2025-09-23 12:41:34.009371|\n",
      "+-------------+------------+-----------+-------------+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Also check current source data timestamps\n",
    "print(\"\\nCurrent source data timestamps:\")\n",
    "spark.sql(f\"\"\"\n",
    "    SELECT \n",
    "        cons_acct_key,\n",
    "        rpt_as_of_mo,\n",
    "        past_due_am,\n",
    "        days_past_due_ct_4in as days_past_due,\n",
    "        base_ts\n",
    "    FROM default.default.accounts_all\n",
    "    WHERE cons_acct_key IN ({','.join(map(str, BACKFILL_ACCOUNTS))})\n",
    "      AND rpt_as_of_mo = '{BACKFILL_MONTH}'\n",
    "    ORDER BY cons_acct_key, base_ts\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Insert Late-Arriving Data\n",
    "\n",
    "Now we'll simulate late-arriving data by inserting new records with:\n",
    "- **Newer timestamp** (current time)\n",
    "- **Modified values** (increased past_due and days_past_due)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T16:45:38.332045Z",
     "iopub.status.busy": "2026-01-21T16:45:38.331107Z",
     "iopub.status.idle": "2026-01-21T16:45:38.340980Z",
     "shell.execute_reply": "2026-01-21T16:45:38.339726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes to apply:\n",
      "  - past_due_am: +10,000\n",
      "  - days_past_due: +30\n"
     ]
    }
   ],
   "source": [
    "# Define the changes we'll make\n",
    "PAST_DUE_INCREASE = 10000  # Add 10,000 to past_due_am\n",
    "DPD_INCREASE = 30          # Add 30 days to days_past_due\n",
    "\n",
    "print(f\"Changes to apply:\")\n",
    "print(f\"  - past_due_am: +{PAST_DUE_INCREASE:,}\")\n",
    "print(f\"  - days_past_due: +{DPD_INCREASE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T16:45:38.345790Z",
     "iopub.status.busy": "2026-01-21T16:45:38.344773Z",
     "iopub.status.idle": "2026-01-21T16:45:39.843761Z",
     "shell.execute_reply": "2026-01-21T16:45:39.841719Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting late-arriving records...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26/01/21 16:45:38 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Insert late-arriving records\n",
    "insert_sql = f\"\"\"\n",
    "INSERT INTO default.default.accounts_all\n",
    "SELECT \n",
    "    cons_acct_key,\n",
    "    bureau_mbr_id,\n",
    "    port_type_cd,\n",
    "    acct_type_dtl_cd,\n",
    "    pymt_terms_cd,\n",
    "    pymt_terms_dtl_cd,\n",
    "    acct_open_dt,\n",
    "    acct_closed_dt,\n",
    "    acct_dt,\n",
    "    last_pymt_dt,\n",
    "    schd_pymt_dt,\n",
    "    orig_pymt_due_dt,\n",
    "    write_off_dt,\n",
    "    acct_stat_cd,\n",
    "    acct_pymt_stat_cd,\n",
    "    acct_pymt_stat_dtl_cd,\n",
    "    acct_credit_ext_am,\n",
    "    acct_bal_am,\n",
    "    past_due_am + {PAST_DUE_INCREASE} as past_due_am,\n",
    "    actual_pymt_am,\n",
    "    next_schd_pymt_am,\n",
    "    write_off_am,\n",
    "    asset_class_cd_4in,\n",
    "    days_past_due_ct_4in + {DPD_INCREASE} as days_past_due_ct_4in,\n",
    "    high_credit_am_4in,\n",
    "    cash_limit_am_4in,\n",
    "    collateral_am_4in,\n",
    "    total_write_off_am_4in,\n",
    "    principal_write_off_am_4in,\n",
    "    settled_am_4in,\n",
    "    interest_rate_4in,\n",
    "    suit_filed_wilful_def_stat_cd_4in,\n",
    "    wo_settled_stat_cd_4in,\n",
    "    collateral_cd,\n",
    "    rpt_as_of_mo,\n",
    "    current_timestamp() as base_ts\n",
    "FROM default.default.accounts_all\n",
    "WHERE rpt_as_of_mo = '{BACKFILL_MONTH}' \n",
    "  AND cons_acct_key IN ({','.join(map(str, BACKFILL_ACCOUNTS))})\n",
    "\"\"\"\n",
    "\n",
    "print(\"Inserting late-arriving records...\")\n",
    "spark.sql(insert_sql)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T16:45:39.849844Z",
     "iopub.status.busy": "2026-01-21T16:45:39.848685Z",
     "iopub.status.idle": "2026-01-21T16:45:40.397111Z",
     "shell.execute_reply": "2026-01-21T16:45:40.395306Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Source data after insertion (showing both old and new records):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+-----------+-------------+--------------------------+-----------------------+\n",
      "|cons_acct_key|rpt_as_of_mo|past_due_am|days_past_due|base_ts                   |record_type            |\n",
      "+-------------+------------+-----------+-------------+--------------------------+-----------------------+\n",
      "|11           |2024-03     |38524      |48           |2025-09-23 12:41:34.009371|(original)             |\n",
      "|11           |2024-03     |48524      |78           |2026-01-21 16:45:38.494702|<-- NEW (late-arriving)|\n",
      "|12           |2024-03     |14903      |21           |2025-09-23 12:41:34.009371|(original)             |\n",
      "|12           |2024-03     |24903      |51           |2026-01-21 16:45:38.494702|<-- NEW (late-arriving)|\n",
      "|13           |2024-03     |9657       |16           |2025-09-23 12:41:34.009371|(original)             |\n",
      "|13           |2024-03     |19657      |46           |2026-01-21 16:45:38.494702|<-- NEW (late-arriving)|\n",
      "|14           |2024-03     |27889      |74           |2025-09-23 12:41:34.009371|(original)             |\n",
      "|14           |2024-03     |37889      |104          |2026-01-21 16:45:38.494702|<-- NEW (late-arriving)|\n",
      "|15           |2024-03     |56596      |41           |2025-09-23 12:41:34.009371|(original)             |\n",
      "|15           |2024-03     |66596      |71           |2026-01-21 16:45:38.494702|<-- NEW (late-arriving)|\n",
      "+-------------+------------+-----------+-------------+--------------------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verify the new records were inserted\n",
    "print(\"\\nSource data after insertion (showing both old and new records):\")\n",
    "spark.sql(f\"\"\"\n",
    "    SELECT \n",
    "        cons_acct_key,\n",
    "        rpt_as_of_mo,\n",
    "        past_due_am,\n",
    "        days_past_due_ct_4in as days_past_due,\n",
    "        base_ts,\n",
    "        CASE \n",
    "            WHEN base_ts > timestamp'2026-01-21 16:00:00' THEN '<-- NEW (late-arriving)'\n",
    "            ELSE '(original)'\n",
    "        END as record_type\n",
    "    FROM default.default.accounts_all\n",
    "    WHERE cons_acct_key IN ({','.join(map(str, BACKFILL_ACCOUNTS))})\n",
    "      AND rpt_as_of_mo = '{BACKFILL_MONTH}'\n",
    "    ORDER BY cons_acct_key, base_ts\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Run Backfill Pipeline\n",
    "\n",
    "Now we'll run the backfill to process the late-arriving data using direct Spark SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T16:45:40.409643Z",
     "iopub.status.busy": "2026-01-21T16:45:40.406790Z",
     "iopub.status.idle": "2026-01-21T16:45:41.433104Z",
     "shell.execute_reply": "2026-01-21T16:45:41.431391Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running backfill processing...\n",
      "============================================================\n",
      "\n",
      "1. Getting latest records for affected accounts...\n",
      "   Created temp view with latest records\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+--------------------+--------------------+\n",
      "|cons_acct_key|past_due_am|days_past_due_ct_4in|             base_ts|\n",
      "+-------------+-----------+--------------------+--------------------+\n",
      "|           11|      48524|                  78|2026-01-21 16:45:...|\n",
      "|           12|      24903|                  51|2026-01-21 16:45:...|\n",
      "|           13|      19657|                  46|2026-01-21 16:45:...|\n",
      "|           14|      37889|                 104|2026-01-21 16:45:...|\n",
      "|           15|      66596|                  71|2026-01-21 16:45:...|\n",
      "+-------------+-----------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run backfill using direct SQL approach\n",
    "print(\"Running backfill processing...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Step 1: Get the latest records for the backfill month (by base_ts)\n",
    "print(\"\\n1. Getting latest records for affected accounts...\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE OR REPLACE TEMP VIEW latest_source AS\n",
    "    SELECT *\n",
    "    FROM (\n",
    "        SELECT *,\n",
    "               ROW_NUMBER() OVER (PARTITION BY cons_acct_key ORDER BY base_ts DESC) as rn\n",
    "        FROM default.default.accounts_all\n",
    "        WHERE rpt_as_of_mo = '{BACKFILL_MONTH}'\n",
    "          AND cons_acct_key IN ({','.join(map(str, BACKFILL_ACCOUNTS))})\n",
    "    )\n",
    "    WHERE rn = 1\n",
    "\"\"\")\n",
    "\n",
    "print(\"   Created temp view with latest records\")\n",
    "\n",
    "# Show latest records\n",
    "spark.sql(\"\"\"\n",
    "    SELECT cons_acct_key, past_due_am, days_past_due_ct_4in, base_ts \n",
    "    FROM latest_source\n",
    "    ORDER BY cons_acct_key\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T16:45:41.440847Z",
     "iopub.status.busy": "2026-01-21T16:45:41.439199Z",
     "iopub.status.idle": "2026-01-21T16:45:46.379282Z",
     "shell.execute_reply": "2026-01-21T16:45:46.377078Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Updating summary table with MERGE...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MERGE completed successfully!\n",
      "\n",
      "============================================================\n",
      "BACKFILL COMPLETE!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Update the summary table using MERGE\n",
    "print(\"\\n2. Updating summary table with MERGE...\")\n",
    "\n",
    "merge_sql = f\"\"\"\n",
    "MERGE INTO default.summary AS target\n",
    "USING (\n",
    "    SELECT \n",
    "        s.cons_acct_key,\n",
    "        '{BACKFILL_MONTH}' as rpt_as_of_mo,\n",
    "        ls.past_due_am as new_past_due_am,\n",
    "        ls.days_past_due_ct_4in as new_days_past_due\n",
    "    FROM latest_source ls\n",
    "    JOIN default.summary s \n",
    "        ON ls.cons_acct_key = s.cons_acct_key \n",
    "        AND s.rpt_as_of_mo = '{BACKFILL_MONTH}'\n",
    ") AS source\n",
    "ON target.cons_acct_key = source.cons_acct_key \n",
    "   AND target.rpt_as_of_mo = source.rpt_as_of_mo\n",
    "WHEN MATCHED THEN UPDATE SET\n",
    "    target.past_due_am = source.new_past_due_am,\n",
    "    target.days_past_due = source.new_days_past_due,\n",
    "    target.past_due_am_history = array(source.new_past_due_am, target.past_due_am_history[1], target.past_due_am_history[2], target.past_due_am_history[3], target.past_due_am_history[4], target.past_due_am_history[5], target.past_due_am_history[6], target.past_due_am_history[7], target.past_due_am_history[8], target.past_due_am_history[9], target.past_due_am_history[10], target.past_due_am_history[11], target.past_due_am_history[12], target.past_due_am_history[13], target.past_due_am_history[14], target.past_due_am_history[15], target.past_due_am_history[16], target.past_due_am_history[17], target.past_due_am_history[18], target.past_due_am_history[19], target.past_due_am_history[20], target.past_due_am_history[21], target.past_due_am_history[22], target.past_due_am_history[23], target.past_due_am_history[24], target.past_due_am_history[25], target.past_due_am_history[26], target.past_due_am_history[27], target.past_due_am_history[28], target.past_due_am_history[29], target.past_due_am_history[30], target.past_due_am_history[31], target.past_due_am_history[32], target.past_due_am_history[33], target.past_due_am_history[34], target.past_due_am_history[35]),\n",
    "    target.days_past_due_history = array(source.new_days_past_due, target.days_past_due_history[1], target.days_past_due_history[2], target.days_past_due_history[3], target.days_past_due_history[4], target.days_past_due_history[5], target.days_past_due_history[6], target.days_past_due_history[7], target.days_past_due_history[8], target.days_past_due_history[9], target.days_past_due_history[10], target.days_past_due_history[11], target.days_past_due_history[12], target.days_past_due_history[13], target.days_past_due_history[14], target.days_past_due_history[15], target.days_past_due_history[16], target.days_past_due_history[17], target.days_past_due_history[18], target.days_past_due_history[19], target.days_past_due_history[20], target.days_past_due_history[21], target.days_past_due_history[22], target.days_past_due_history[23], target.days_past_due_history[24], target.days_past_due_history[25], target.days_past_due_history[26], target.days_past_due_history[27], target.days_past_due_history[28], target.days_past_due_history[29], target.days_past_due_history[30], target.days_past_due_history[31], target.days_past_due_history[32], target.days_past_due_history[33], target.days_past_due_history[34], target.days_past_due_history[35])\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(merge_sql)\n",
    "print(\"   MERGE completed successfully!\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"BACKFILL COMPLETE!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Check State AFTER Backfill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T16:45:46.386733Z",
     "iopub.status.busy": "2026-01-21T16:45:46.386077Z",
     "iopub.status.idle": "2026-01-21T16:45:46.863628Z",
     "shell.execute_reply": "2026-01-21T16:45:46.861917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "AFTER BACKFILL - State for 2024-03\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cons_acct_key</th>\n",
       "      <th>rpt_as_of_mo</th>\n",
       "      <th>past_due_am</th>\n",
       "      <th>days_past_due</th>\n",
       "      <th>balance_am</th>\n",
       "      <th>payment_history_grid</th>\n",
       "      <th>past_due_latest</th>\n",
       "      <th>dpd_latest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>2024-03</td>\n",
       "      <td>48524</td>\n",
       "      <td>78</td>\n",
       "      <td>80259</td>\n",
       "      <td>110?????????????????????????????????</td>\n",
       "      <td>48524</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>2024-03</td>\n",
       "      <td>24903</td>\n",
       "      <td>51</td>\n",
       "      <td>70968</td>\n",
       "      <td>000?????????????????????????????????</td>\n",
       "      <td>24903</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>2024-03</td>\n",
       "      <td>19657</td>\n",
       "      <td>46</td>\n",
       "      <td>60361</td>\n",
       "      <td>000?????????????????????????????????</td>\n",
       "      <td>19657</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>2024-03</td>\n",
       "      <td>37889</td>\n",
       "      <td>104</td>\n",
       "      <td>55779</td>\n",
       "      <td>200?????????????????????????????????</td>\n",
       "      <td>37889</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>2024-03</td>\n",
       "      <td>66596</td>\n",
       "      <td>71</td>\n",
       "      <td>138040</td>\n",
       "      <td>100?????????????????????????????????</td>\n",
       "      <td>66596</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cons_acct_key rpt_as_of_mo  past_due_am  days_past_due  balance_am  \\\n",
       "0             11      2024-03        48524             78       80259   \n",
       "1             12      2024-03        24903             51       70968   \n",
       "2             13      2024-03        19657             46       60361   \n",
       "3             14      2024-03        37889            104       55779   \n",
       "4             15      2024-03        66596             71      138040   \n",
       "\n",
       "                   payment_history_grid  past_due_latest  dpd_latest  \n",
       "0  110?????????????????????????????????            48524          78  \n",
       "1  000?????????????????????????????????            24903          51  \n",
       "2  000?????????????????????????????????            19657          46  \n",
       "3  200?????????????????????????????????            37889         104  \n",
       "4  100?????????????????????????????????            66596          71  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get AFTER state\n",
    "after_df = spark.sql(f\"\"\"\n",
    "    SELECT \n",
    "        cons_acct_key,\n",
    "        rpt_as_of_mo,\n",
    "        past_due_am,\n",
    "        days_past_due,\n",
    "        balance_am,\n",
    "        payment_history_grid,\n",
    "        past_due_am_history[0] as past_due_latest,\n",
    "        days_past_due_history[0] as dpd_latest\n",
    "    FROM default.summary\n",
    "    WHERE cons_acct_key IN ({','.join(map(str, BACKFILL_ACCOUNTS))})\n",
    "      AND rpt_as_of_mo = '{BACKFILL_MONTH}'\n",
    "    ORDER BY cons_acct_key\n",
    "\"\"\")\n",
    "\n",
    "after_state = after_df.toPandas()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"AFTER BACKFILL - State for {BACKFILL_MONTH}\")\n",
    "print(\"=\" * 80)\n",
    "after_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Compare BEFORE vs AFTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T16:45:46.869803Z",
     "iopub.status.busy": "2026-01-21T16:45:46.868577Z",
     "iopub.status.idle": "2026-01-21T16:45:46.914640Z",
     "shell.execute_reply": "2026-01-21T16:45:46.913228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "COMPARISON: BEFORE vs AFTER BACKFILL\n",
      "====================================================================================================\n",
      "\n",
      "Expected changes: past_due +10,000, days_past_due +30\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cons_acct_key</th>\n",
       "      <th>past_due_am_BEFORE</th>\n",
       "      <th>past_due_am_AFTER</th>\n",
       "      <th>past_due_DIFF</th>\n",
       "      <th>days_past_due_BEFORE</th>\n",
       "      <th>days_past_due_AFTER</th>\n",
       "      <th>dpd_DIFF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>38524</td>\n",
       "      <td>48524</td>\n",
       "      <td>10000</td>\n",
       "      <td>48</td>\n",
       "      <td>78</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>14903</td>\n",
       "      <td>24903</td>\n",
       "      <td>10000</td>\n",
       "      <td>21</td>\n",
       "      <td>51</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>9657</td>\n",
       "      <td>19657</td>\n",
       "      <td>10000</td>\n",
       "      <td>16</td>\n",
       "      <td>46</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>27889</td>\n",
       "      <td>37889</td>\n",
       "      <td>10000</td>\n",
       "      <td>74</td>\n",
       "      <td>104</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>56596</td>\n",
       "      <td>66596</td>\n",
       "      <td>10000</td>\n",
       "      <td>41</td>\n",
       "      <td>71</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cons_acct_key  past_due_am_BEFORE  past_due_am_AFTER  past_due_DIFF  \\\n",
       "0             11               38524              48524          10000   \n",
       "1             12               14903              24903          10000   \n",
       "2             13                9657              19657          10000   \n",
       "3             14               27889              37889          10000   \n",
       "4             15               56596              66596          10000   \n",
       "\n",
       "   days_past_due_BEFORE  days_past_due_AFTER  dpd_DIFF  \n",
       "0                    48                   78        30  \n",
       "1                    21                   51        30  \n",
       "2                    16                   46        30  \n",
       "3                    74                  104        30  \n",
       "4                    41                   71        30  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create comparison dataframe\n",
    "import pandas as pd\n",
    "\n",
    "comparison = pd.merge(\n",
    "    before_state[['cons_acct_key', 'past_due_am', 'days_past_due', 'payment_history_grid']],\n",
    "    after_state[['cons_acct_key', 'past_due_am', 'days_past_due', 'payment_history_grid']],\n",
    "    on='cons_acct_key',\n",
    "    suffixes=('_BEFORE', '_AFTER')\n",
    ")\n",
    "\n",
    "# Calculate differences\n",
    "comparison['past_due_DIFF'] = comparison['past_due_am_AFTER'] - comparison['past_due_am_BEFORE']\n",
    "comparison['dpd_DIFF'] = comparison['days_past_due_AFTER'] - comparison['days_past_due_BEFORE']\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"COMPARISON: BEFORE vs AFTER BACKFILL\")\n",
    "print(\"=\" * 100)\n",
    "print(f\"\\nExpected changes: past_due +{PAST_DUE_INCREASE:,}, days_past_due +{DPD_INCREASE}\")\n",
    "print()\n",
    "\n",
    "comparison[['cons_acct_key', 'past_due_am_BEFORE', 'past_due_am_AFTER', 'past_due_DIFF', \n",
    "            'days_past_due_BEFORE', 'days_past_due_AFTER', 'dpd_DIFF']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T16:45:46.918160Z",
     "iopub.status.busy": "2026-01-21T16:45:46.917576Z",
     "iopub.status.idle": "2026-01-21T16:45:46.926708Z",
     "shell.execute_reply": "2026-01-21T16:45:46.925453Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "VERIFICATION\n",
      "============================================================\n",
      "\n",
      "past_due_am increased by 10,000 for all accounts: YES\n",
      "days_past_due increased by 30 for all accounts: YES\n",
      "\n",
      "****************************************\n",
      "BACKFILL SIMULATION SUCCESSFUL!\n",
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "# Verify the changes match expected\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"VERIFICATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "all_past_due_correct = (comparison['past_due_DIFF'] == PAST_DUE_INCREASE).all()\n",
    "all_dpd_correct = (comparison['dpd_DIFF'] == DPD_INCREASE).all()\n",
    "\n",
    "print(f\"\\npast_due_am increased by {PAST_DUE_INCREASE:,} for all accounts: \", end=\"\")\n",
    "print(\"YES\" if all_past_due_correct else \"NO\")\n",
    "\n",
    "print(f\"days_past_due increased by {DPD_INCREASE} for all accounts: \", end=\"\")\n",
    "print(\"YES\" if all_dpd_correct else \"NO\")\n",
    "\n",
    "if all_past_due_correct and all_dpd_correct:\n",
    "    print(\"\\n\" + \"*\" * 40)\n",
    "    print(\"BACKFILL SIMULATION SUCCESSFUL!\")\n",
    "    print(\"*\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Check Rolling History Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T16:45:46.931952Z",
     "iopub.status.busy": "2026-01-21T16:45:46.930272Z",
     "iopub.status.idle": "2026-01-21T16:45:47.350111Z",
     "shell.execute_reply": "2026-01-21T16:45:47.347873Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ROLLING HISTORY ARRAYS - First backfilled account\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------------------------------+-------------------------------------+---------------------------------+\n",
      "|rpt_as_of_mo|payment_history_grid                |past_due_6mo                         |dpd_6mo                          |\n",
      "+------------+------------------------------------+-------------------------------------+---------------------------------+\n",
      "|2024-01     |0???????????????????????????????????|[0, NULL, NULL, NULL, NULL, NULL]    |[0, NULL, NULL, NULL, NULL, NULL]|\n",
      "|2024-02     |10??????????????????????????????????|[23208, 0, NULL, NULL, NULL, NULL]   |[30, 0, NULL, NULL, NULL, NULL]  |\n",
      "|2024-03     |110?????????????????????????????????|[48524, 23208, 0, NULL, NULL, NULL]  |[78, 30, 0, NULL, NULL, NULL]    |\n",
      "|2024-04     |1110????????????????????????????????|[45694, 38524, 23208, 0, NULL, NULL] |[40, 48, 30, 0, NULL, NULL]      |\n",
      "|2024-05     |21110???????????????????????????????|[39365, 45694, 38524, 23208, 0, NULL]|[68, 40, 48, 30, 0, NULL]        |\n",
      "|2024-06     |021110??????????????????????????????|[0, 39365, 45694, 38524, 23208, 0]   |[0, 68, 40, 48, 30, 0]           |\n",
      "+------------+------------------------------------+-------------------------------------+---------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check how the history arrays look for the backfilled accounts\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ROLLING HISTORY ARRAYS - First backfilled account\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "first_account = BACKFILL_ACCOUNTS[0]\n",
    "spark.sql(f\"\"\"\n",
    "    SELECT \n",
    "        rpt_as_of_mo,\n",
    "        payment_history_grid,\n",
    "        slice(past_due_am_history, 1, 6) as past_due_6mo,\n",
    "        slice(days_past_due_history, 1, 6) as dpd_6mo\n",
    "    FROM default.summary\n",
    "    WHERE cons_acct_key = {first_account}\n",
    "    ORDER BY rpt_as_of_mo\n",
    "\"\"\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T16:45:47.355481Z",
     "iopub.status.busy": "2026-01-21T16:45:47.354010Z",
     "iopub.status.idle": "2026-01-21T16:45:48.005430Z",
     "shell.execute_reply": "2026-01-21T16:45:48.004236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FINAL TABLE COUNTS\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accounts_all:   5,995 records (includes new late-arriving records)\n",
      "summary:        5,950 records (unchanged count, but values updated)\n",
      "latest_summary: 1,000 records\n"
     ]
    }
   ],
   "source": [
    "# Final table counts\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FINAL TABLE COUNTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "accounts_count = spark.sql(\"SELECT COUNT(*) as cnt FROM default.default.accounts_all\").collect()[0]['cnt']\n",
    "summary_count = spark.sql(\"SELECT COUNT(*) as cnt FROM default.summary\").collect()[0]['cnt']\n",
    "latest_count = spark.sql(\"SELECT COUNT(*) as cnt FROM default.latest_summary\").collect()[0]['cnt']\n",
    "\n",
    "print(f\"accounts_all:   {accounts_count:,} records (includes new late-arriving records)\")\n",
    "print(f\"summary:        {summary_count:,} records (unchanged count, but values updated)\")\n",
    "print(f\"latest_summary: {latest_count:,} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Before State**: Showed the original data for selected accounts\n",
    "2. **Late-Arriving Data**: Inserted new records with newer timestamps and modified values\n",
    "3. **Backfill Execution**: Ran MERGE to update the summary table\n",
    "4. **After State**: Verified the summary was updated with the new values\n",
    "5. **Comparison**: Confirmed the exact changes were applied\n",
    "\n",
    "### Key Points:\n",
    "- The pipeline uses `base_ts` (timestamp) to determine which record is the \"winner\"\n",
    "- Newer records override older records for the same account/month\n",
    "- Rolling history arrays are updated to reflect the new values\n",
    "- The summary table record count stays the same (update, not insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-21T16:45:48.011636Z",
     "iopub.status.busy": "2026-01-21T16:45:48.010617Z",
     "iopub.status.idle": "2026-01-21T16:45:48.114872Z",
     "shell.execute_reply": "2026-01-21T16:45:48.112555Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temp views cleaned up.\n",
      "\n",
      "Notebook execution complete!\n"
     ]
    }
   ],
   "source": [
    "# Cleanup temp views\n",
    "spark.catalog.dropTempView(\"latest_source\")\n",
    "print(\"Temp views cleaned up.\")\n",
    "print(\"\\nNotebook execution complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
